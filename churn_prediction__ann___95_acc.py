# -*- coding: utf-8 -*-
"""Churn Prediction| ANN | 95% Acc

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/#fileId=https%3A//storage.googleapis.com/kaggle-colab-exported-notebooks/churn-prediction-ann-95-acc-c334475e-2afa-4807-94bc-5889393b4718.ipynb%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com/20241015/auto/storage/goog4_request%26X-Goog-Date%3D20241015T053734Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D12c20b66e2b811cf8a881b47bedfd63ab04631ca1d6dd5cfb3e385b85063fb54ab6704f7632f18996a63792d2232417117fe3258e9533342018fd473060adf44b78f72812ace62b312af20418311d9d74fb4526f980c28058b34c06de42c39189f4c96e7e4865687c47f3d9601412c52b94dd7f4f017af6546a14d45cf8430684ac2050e34122e3ab92bef5d83855a457c822529dfe9600841ca21b7caece85e49d53fef0fb67c7003180e863f3b0f34dbe1bf65662d91ce12ec237331f2815b0e75ff4076513417b40a88f20ea10a53b61bff3428b9b6b8a56f9dedcb9c4b5f2a920eaad36e5006cc459f4d2967a477235ce1a9dc84354c8834ac483adec487
"""

import numpy as np # linear algebra
import pandas as pd
import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

df = pd.read_csv('/kaggle/input/telecom-churn/telecom_churn.csv')

df.head()

df.shape

df.isna().sum()

df.duplicated().sum()

import seaborn as sns
import matplotlib.pyplot as plt

df.corr()['Churn']

labels = df['Churn'].value_counts().index
sizes = df['Churn'].value_counts().values

plt.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=140)
plt.show()

sns.countplot(df,x = 'DataPlan',palette = 'Set2')

sns.countplot(df,x = 'CustServCalls',palette = 'Set1')

from sklearn.model_selection import train_test_split

X = df.drop(['Churn'],axis = 1)
y = df['Churn']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()

X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.fit_transform(X_test)

import tensorflow
from tensorflow import keras
from keras import Sequential
from keras.layers import Dense,Input,Dropout,BatchNormalization

model = Sequential()

model.add(Input(shape=(10,)))
model.add(Dense(256,activation = 'relu'))
model.add(BatchNormalization())
model.add(Dense(128,activation = 'relu'))
model.add(BatchNormalization())
model.add(Dropout(0.25))
model.add(Dense(1,activation = 'sigmoid'))

model.compile(optimizer = 'adam',loss = 'binary_crossentropy',metrics = ['precision','accuracy'])

r = model.fit(X_train_scaled,y_train,epochs = 25,validation_data = (X_test_scaled,y_test),batch_size = 33)

plt.plot(r.history['loss'],color = 'red')
plt.plot(r.history['val_loss'])

plt.plot(r.history['precision'],color = 'green')
plt.plot(r.history['val_precision'])

plt.plot(r.history['accuracy'],color = 'green')
plt.plot(r.history['val_accuracy'])

y_pred = model.predict(X_test_scaled)

y_pred_new = []

for num in y_pred:
    if num > 0.6:
        num = 1
        y_pred_new.append(num)
    else:
        num = 0
        y_pred_new.append(num)

from sklearn.metrics import accuracy_score,precision_score
print(accuracy_score(y_test,y_pred_new))
print(precision_score(y_test,y_pred_new))



